{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"\n",
    "You are a bot that generates SQLite SQL.\n",
    "\n",
    "RULES:\n",
    "- Return ONLY the SQL query (no explanations, no markdown, no backticks).\n",
    "- Use only the tables/columns provided below.\n",
    "- If the request cannot be answered with this schema, return exactly: NEED_MORE_SCHEMA\n",
    "    \"\"\"},\n",
    "\n",
    "    {\"role\": \"system\", \"content\": \"\"\"\n",
    "TABLE employees(\n",
    "  ID_usr INTEGER,\n",
    "  name TEXT\n",
    ");\n",
    "\n",
    "TABLE salary(\n",
    "  ID_usr INTEGER,\n",
    "  year INTEGER,\n",
    "  salary REAL\n",
    ");\n",
    "\n",
    "TABLE studies(\n",
    "  ID INTEGER,\n",
    "  ID_usr INTEGER,\n",
    "  educational_level INTEGER,\n",
    "  Institution TEXT,\n",
    "  Years INTEGER,\n",
    "  Speciality TEXT\n",
    ");\n",
    "    \"\"\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "context.append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "EXAMPLES (convert question -> SQL):\n",
    "\n",
    "Q: Show each employee name with their salary for year 2023.\n",
    "A: SELECT e.name, s.salary\n",
    "   FROM employees e\n",
    "   JOIN salary s ON e.ID_usr = s.ID_usr\n",
    "   WHERE s.year = 2023;\n",
    "\n",
    "Q: List the top 5 highest salaries with employee names (any year).\n",
    "A: SELECT e.name, s.year, s.salary\n",
    "   FROM employees e\n",
    "   JOIN salary s ON e.ID_usr = s.ID_usr\n",
    "   ORDER BY s.salary DESC\n",
    "   LIMIT 5;\n",
    "\n",
    "Q: Show employees who studied at 'Harvard'.\n",
    "A: SELECT DISTINCT e.name\n",
    "   FROM employees e\n",
    "   JOIN studies st ON e.ID_usr = st.ID_usr\n",
    "   WHERE st.Institution = 'Harvard';\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT e.name, s.salary\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "WHERE s.year = 2023;\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"Show each employee name with their salary for year 2023.\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT e.name, s.salary\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "WHERE s.year = '2023';\n",
      "```\n",
      "\n",
      "This SQL query retrieves the name of each employee along with their salary for the year 2023 by joining the \"employees\" table with the \"salary\" table on the employee ID and filtering the results to only include salaries for the year 2023.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"Show each employee name with their salary for year 2023.\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT year, AVG(salary) AS average_salary\n",
      "FROM salary\n",
      "GROUP BY year\n",
      "ORDER BY year;\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"Show the average salary per year, sorted by year.\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT year, AVG(salary) AS average_salary\n",
      "FROM salary\n",
      "GROUP BY year\n",
      "ORDER BY year;\n",
      "```\n",
      "\n",
      "This SQL query selects the year and calculates the average salary for each year from the \"salary\" table. It groups the results by year, calculates the average salary for each year, and then sorts the results in ascending order by year.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"Show the average salary per year, sorted by year.\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132bb14",
   "metadata": {},
   "source": [
    "# NL2SQL Prompt Variations — Findings Report\n",
    "Schema used across tests: employees, salary, studies (SQLite)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1052a3",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Goal: compare prompt styles for converting natural language questions into valid SQLite SQL.\n",
    "I tested multiple prompts using the same tables to keep the comparison fair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b559f",
   "metadata": {},
   "source": [
    "## Version 1 (Old / baseline prompt)\n",
    "Behavior: often outputs SQL plus extra explanation and sometimes code fences.\n",
    "Pro: easy to read.\n",
    "Con: noisy if you need SQL-only output for automation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086f0b3",
   "metadata": {},
   "source": [
    "## Version 2 (New prompt: schema + SQL-only rule)\n",
    "Behavior: usually returns only the SQL query.\n",
    "Pro: clean output that’s easy to reuse.\n",
    "Con: if the schema is missing from context, it asks for tables instead of generating SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d039a",
   "metadata": {},
   "source": [
    "## Version 3 (New prompt + few-shot examples + refusal rule)\n",
    "Behavior: most consistent SQL-only output.\n",
    "Pro: few-shot examples improve formatting consistency.\n",
    "Pro: refusal rule reduces hallucination when schema is insufficient (NEED_MORE_SCHEMA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00049f64",
   "metadata": {},
   "source": [
    "## Variations that didn’t work well\n",
    "- When table definitions weren’t included (or I reused a stale context copy), the model asked for tables instead of producing SQL.\n",
    "- The old prompt sometimes mixed SQL with explanation/formatting, which is inconvenient for pipelines expecting raw SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a9e3e",
   "metadata": {},
   "source": [
    "## What I learned\n",
    "- The schema must be in the prompt context for reliable NL2SQL.\n",
    "- “Return ONLY SQL” is a strong constraint that improves usability.\n",
    "- Few-shot examples help keep outputs consistent.\n",
    "- Recreating `context_user = context.copy()` per test cell avoids stale-context errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011610c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Best overall: Version 3 (schema + SQL-only + few-shot + refusal rule).\n",
    "It produced the cleanest outputs and reduced failure cases / hallucinations."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
